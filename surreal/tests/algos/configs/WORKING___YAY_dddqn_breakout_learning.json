{
  "gamma": 0.99,

  "n_step": 4,

  "memory_capacity": 100000,  # this is too high, makes PC (currently 24Gb RAM) crash
  "memory_batch_size": 256,

  "epsilon": {
    "type": "linear-decay",
    "from": 1.0,
    "to": 0.0,  # <- this is probably a bad idea, should be 0.1, but did learn anyway
    "end_time_percentage": 0.1
  },

  "q_network": [
    {
      "name": "conv2d",
      "filters": 16,
      "kernel_size": 8,
      "strides": 4,
      "padding": "same",
      "activation": "relu"
    },
    {
      "name": "conv2d",
      "filters": 32,
      "kernel_size": 4,
      "strides": 2,
      "padding": "same",
      "activation": "relu"
    },
    {
      "name": "conv2d",
      "filters": 256,
      "kernel_size": 11,
      "strides": 1,
      "padding": "valid",
      "activation": "relu"
    },
    {
      "name": "flatten"
    },
    {
      "name": "dense",
      "units": 512,
      "activation": "relu"
    }
  ],

  "dueling_a_network": [
    {
      "name": "dense",
      "units": 64,
      "activation": "relu"
    }
  ],

  "dueling_v_network": [
    {
      "name": "dense",
      "units": 64,
      "activation": "relu"
    }
  ],

  "update_frequency": 32,
  "steps_before_update": "when-memory-ready",
  "sync_frequency": 10000,

  "optimizer": {
    "type": "adam",
    "learning_rate": 0.0002,
    "clip_norm": 40
  }
}
